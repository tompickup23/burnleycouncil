# Article Pipeline Audit & Improvement Plan

> Audit date: 9 February 2026
> Scope: AI DOGE articles, News Lancashire pipeline, News Burnley

---

## 1. Current Architecture

```
┌─────────────────────────────────────────────────────────────────────────┐
│                        THREE ARTICLE SYSTEMS                           │
├─────────────────────┬──────────────────────┬───────────────────────────┤
│  AI DOGE            │  News Lancashire     │  News Burnley             │
│  (spending articles)│  (local news)        │  (Burnley news subset)    │
├─────────────────────┼──────────────────────┼───────────────────────────┤
│  article_pipeline.py│  pipeline_v4.sh      │  news_burnley_sync.py     │
│  on vps-main        │  on vps-news         │  on vps-news              │
│  Cron: 9am daily    │  Cron: every 30 min  │  Phase 9 of pipeline_v4   │
│  LLM: llm_router.py│  LLM: ai_rewriter.py │  Zero AI (filter only)    │
│                     │       ai_analyzer.py │                           │
├─────────────────────┼──────────────────────┼───────────────────────────┤
│  Output:            │  Output:             │  Output:                  │
│  articles-index.json│  SQLite → Hugo site  │  index.html + JSON        │
│  + article/*.json   │  → Cloudflare Pages  │  → Cloudflare Pages       │
│  (per council)      │  (newslancashire)    │  (newsburnley)            │
├─────────────────────┼──────────────────────┼───────────────────────────┤
│  Deploy:            │  Deploy:             │  Deploy:                  │
│  Git push → GH      │  deploy_newslancs.sh │  deploy_newsburnley.sh    │
│  Actions → GH Pages│  vps-main 10am cron  │  vps-main 10:30am cron    │
└─────────────────────┴──────────────────────┴───────────────────────────┘
```

### Cron Timeline (daily)

```
vps-news (every 30 min):
  */30  pipeline_v4.sh ─► crawl → AI rewrite → AI analyze → export → News Burnley sync

vps-main (sequential):
  05:00  sync_repos.sh (git pull + rsync scripts to vps-news)
  07:00  data_monitor.py (check councils for new spending CSVs)
  08:00  auto_pipeline.py (SSH → vps-news ETL → DOGE analysis)
  09:00  article_pipeline.py (AI DOGE spending articles via LLM)
  10:00  deploy_newslancashire.sh (Hugo build on vps-news → wrangler from vps-main)
  10:30  deploy_newsburnley.sh (rsync from vps-news → wrangler from vps-main)
```

---

## 2. Pipeline-by-Pipeline Analysis

### 2A. AI DOGE — `article_pipeline.py`

**What it does:** Analyses council spending data to discover article topics, generates fact-checked articles via LLM, updates articles-index.json.

**Current state:**
- Burnley: 44 articles (44 JSON files in articles/ dir)
- Hyndburn: 20 articles
- Pendle: 19 articles
- Rossendale: 6 articles (weakest)
- Topic discovery: 5 fixed topic types (supplier concentration, department spending, DOGE findings, spending trends, micro-spending)
- LLM chain: Mistral Small (free, EU/GDPR-safe) → Groq Llama 3.3 70B → Cerebras → Ollama local (updated 18 Feb 2026 via llm_router.py)
- Verification: basic structure checks only (word count, required sections, no h1)

**Issues found:**

| # | Severity | Issue |
|---|----------|-------|
| 1 | **HIGH** | **Topic exhaustion** — Only 5 topic templates, all keyed by `{topic}-{year}`. Once all 5 run for a council in 2026, no new topics until 2027. Pipeline becomes a no-op for the rest of the year. |
| 2 | **HIGH** | **No git push after generation** — Articles are written to disk on vps-main but never committed/pushed. The React app reads from GH Pages, so articles generated by the cron never reach the live site. Manual `git add + commit + push` is needed each time. |
| 3 | **MED** | **Fact verification is shallow** — `verify_article()` only checks structure (word count, sections). It doesn't verify that £ figures in the output match the data brief. The LLM could hallucinate numbers. |
| 4 | **MED** | **Loading full spending.json into memory** — On vps-main, `load_spending_data()` reads the entire 15-40MB spending.json per council (4 councils = up to 160MB). Could use v3 chunked files or pre-computed stats. |
| 5 | **LOW** | **No deduplication by content** — Only checks article ID. If topic IDs are changed/renamed, could generate duplicate content under new IDs. |
| 6 | **LOW** | **Hardcoded image paths** — `ARTICLE_IMAGES` dict references `/images/articles/*.jpg` but these images may not exist in all council builds. |

### 2B. News Lancashire — `pipeline_v4.sh` + 20+ scripts

**What it does:** Crawls RSS, Bluesky, Google News, Parliament, police API → SQLite → AI rewrite → AI analysis → export JSON → Hugo build → Cloudflare Pages.

**Current state:**
- 961 articles in SQLite DB
- 800 exported to JSON (export cap?)
- AI rewrite: 949/961 done (98.8%)
- AI analysis: 125/961 done (13% — only articles scoring 60+)
- Content tiers: 783 aggregated, 125 analysis, 50 digest, 3 data-driven
- Sources: RSS (673), Bluesky (135), Google News (94), AI digest (49), Parliament (5)
- 9 pipeline phases running every 30 minutes
- Hugo builds 962 pages

**Issues found:**

| # | Severity | Issue |
|---|----------|-------|
| 1 | **HIGH** | **Broken log path** — `pipeline_v4.sh` line 8: `LOG=logs/pipeline.log` but the logs/ dir didn't exist after reboot (had to recreate manually). Cron has been failing silently since OOM crash. |
| 2 | **HIGH** | **Stale Astro reference** — Line ~55 (end of script) still references `newslancashire-astro` dir which was deleted. This is the cd command at the end failing every run. |
| 3 | **HIGH** | **Date format inconsistency** — `published` column has mixed formats: ISO 8601 (`2026-02-09T15:27:15.345Z`) and RFC 2822 (`Sun, 08 Feb 2026 22:01:38 GMT`). 645/787 were migrated to ISO but new RSS articles keep arriving in RFC 2822. Sorting by date will be unreliable. |
| 4 | **MED** | **Export capped at 800** — `export_json.py` calls `export_articles_json()` from crawler_v3.py. May have a LIMIT clause. 961 articles in DB but only 800 exported. 161 articles invisible on the site. |
| 5 | **MED** | **AI rewriter uses batch mode** — Sends 5 articles per API call and splits by `---` delimiter. If the LLM outputs `---` inside a rewrite, parsing breaks and articles get corrupted rewrites. |
| 6 | **MED** | **ai_analyzer model mismatch** — Uses `kimi-latest` model name (line ~79) but ai_rewriter uses `kimi-k2.5`. Inconsistent — `kimi-latest` may be a different model or may not exist. |
| 7 | **MED** | **No Hugo build in pipeline** — pipeline_v4.sh exports JSON but doesn't trigger Hugo build. Hugo build only happens via deploy_newslancashire.sh at 10am. Between 10am and next day's 10am, the site is stale. |
| 8 | **LOW** | **Borough detection gaps** — Lancaster (153) has more articles than Burnley (113). East Lancashire boroughs (Burnley/Hyndburn/Pendle/Rossendale) are underweighted vs. wider Lancashire. |
| 9 | **LOW** | **No duplicate article detection** — Checks by URL hash only. Same story from different sources could appear twice with different URLs. |

### 2C. News Burnley — `news_burnley_sync.py`

**What it does:** Filters News Lancashire export for Burnley-related articles, generates a static HTML page, deploys to Cloudflare Pages.

**Current state:**
- 50 articles (capped at MAX_ARTICLES=50)
- Simple keyword filter: "burnley", "padiham", "brierfield"
- Single-page static HTML (no routing, no pagination)
- Deployed daily at 10:30am from vps-main

**Issues found:**

| # | Severity | Issue |
|---|----------|-------|
| 1 | **MED** | **Only 3 keywords** — Misses Burnley-related content that doesn't mention the town name directly (e.g., "Turf Moor", "Burnley FC", "Burnley Express", council meeting references). |
| 2 | **MED** | **Single page, no SEO** — One index.html with all 50 articles inline. No individual article pages, no sitemap, no structured data. Zero SEO value. |
| 3 | **LOW** | **Hardcoded Cloudflare credentials** — API token and account ID are hardcoded as defaults in both the Python script and the bash deploy script. Should use env vars only. |
| 4 | **LOW** | **No analytics** — No Cloudflare Web Analytics beacon (unlike AI DOGE sites). |
| 5 | **LOW** | **No RSS feed** — No way for readers to subscribe to updates. |

---

## 3. LLM Usage Audit

### Current LLM Routing (updated 10 Feb 2026)

```
AI DOGE articles:     llm_router.py → Mistral Small → Cerebras → Groq → Ollama (updated 18 Feb)
News Lancashire:      ai_rewriter.py  → Gemini 2.5 Flash → Groq* → Kimi → DeepSeek*
                      ai_analyzer.py  → Gemini 2.5 Flash → Groq* → Kimi → DeepSeek*
                      ai_digest_generator.py → Gemini 2.5 Flash → Kimi → DeepSeek*

* Groq blocked from VPS IPs (Cloudflare error 1010). DeepSeek dead (402).
```

**Rate limiter:** `llm_rate_limiter.py` on vps-news tracks daily requests + tokens per provider.
Free tier budget: Gemini 450 req/day (90% of 500), 230K tokens (90% of 250K). Kimi as fallback only.
Pipeline uses ~80 req/day, ~170K tokens — well within free tier.

**Issues (updated):**

| # | Issue | Status |
|---|-------|--------|
| 1 | **Two separate LLM implementations** — `llm_router.py` (5-provider failover with requests lib) vs News Lancashire scripts (4-provider with urllib). Partially consolidated: all News Lancashire scripts now use the same provider chain pattern. | ⚠️ Partial |
| 2 | **Hardcoded API keys in llm_router.py** — All 4 provider keys are hardcoded as defaults. Env vars exist but fall back to hardcoded values. These keys should be rotated (known issue #3 in INFRASTRUCTURE.md). | ❌ Open |
| 3 | **ai_rewriter uses Kimi K2.5 with temperature=1** — Kimi K2.5 API requirement (doesn't accept other values). Correct but limits quality control. | ℹ️ By design |
| 4 | ~~**ai_analyzer uses 0.7 temperature with Kimi**~~ — Fixed: ai_analyzer now uses kimi-k2.5 model (9 Feb night). Temperature handled per-provider. | ✅ Fixed |
| 5 | ~~**No usage tracking for free tiers**~~ — Fixed: `llm_rate_limiter.py` tracks daily requests + tokens per provider with 90% safety margins. Auto-resets daily. | ✅ Fixed |
| 6 | **Groq blocked from VPS IPs** — Cloudflare error 1010 blocks Oracle Cloud + Hostinger IPs. Groq is in the chain but never succeeds server-side. | ❌ Won't fix |
| 7 | **DeepSeek dead** — HTTP 402 Payment Required since ~8 Feb. Credits exhausted. Mitigated by Gemini as free primary. | ⚠️ Mitigated |

---

## 4. Data Structure Review

### AI DOGE Article Format
```json
// articles-index.json (per council)
[{
  "id": "supplier-concentration-2026",
  "date": "2026-02-09",
  "category": "Investigation",
  "title": "Where Burnley's Money Really Goes",
  "summary": "...",
  "image": "/images/articles/outsourcing.jpg",
  "author": "Burnley Council Transparency",
  "tags": []
}]

// articles/{id}.json
{
  "id": "supplier-concentration-2026",
  "content": "<h3>Key Findings</h3>..."  // Raw HTML
}
```

**Issues:** `tags` always empty. No `readTime`, `wordCount`, or `sources` metadata. No link back to data.

### News Lancashire Export Format
```json
[{
  "id": "abc123...",
  "title": "...",
  "link": "https://...",
  "source": "Lancashire Telegraph",
  "source_type": "rss",
  "published": "2026-02-09T15:27:15Z",  // sometimes RFC 2822
  "summary": "...",
  "ai_rewrite": "...",
  "ai_analysis": "...",
  "content_tier": "aggregated|analysis|digest",
  "category": "politics|crime|...",
  "interest_score": 45,
  "trending_score": 64
}]
```

**Issues:** Mixed date formats. No `borough` field in export (only boolean `is_*` columns in DB). Export is flat — Hugo has to re-derive boroughs.

---

## 5. Improvement Plan

### Tier 1 — Critical Fixes (do now)

| # | Fix | Effort | Impact |
|---|-----|--------|--------|
| F1 | ✅ **Fix pipeline_v4.sh** — Added `mkdir -p logs` after cd. No stale Astro reference found (already clean). | 5 min | Stops silent cron failures |
| F2 | ✅ **Export cap — NOT A BUG** — 161 "missing" articles are deduplicated syndicated titles (same RSS story from multiple feeds). LIMIT 2000 is sufficient. 961 total → 800 unique titles. | — | No action needed |
| F3 | ✅ **Fix date normalisation** — Applied `normalise_date_iso()` on INSERT in `insert_article()`. 143 legacy non-ISO dates fixed. All new articles enter DB in ISO 8601. | 15 min | Clean date sorting forever |
| F4 | ✅ **Auto-commit AI DOGE articles** — Added `git_commit_and_push()` to article_pipeline.py. After generation: `git pull --ff-only` → `git add` articles + index → `git commit` → `git push origin main` → triggers CI/CD deploy. `--no-push` flag available. | 20 min | Articles actually appear on aidoge.co.uk |

### Tier 2 — Efficiency Improvements (this week)

| # | Improvement | Effort | Impact |
|---|-------------|--------|--------|
| E1 | **Consolidate LLM routing** — ⚠️ Partially done (10 Feb). All 3 News Lancashire scripts now use same 4-provider fallback chain pattern (Gemini → Groq → Kimi → DeepSeek) with `llm_rate_limiter.py`. Still uses urllib (not llm_router.py). Full consolidation to a single shared module is future work. | 1 hr | Unified LLM management |
| E2 | **Add topic templates to article_pipeline.py** — Beyond the 5 current topics: cross-council comparison articles, quarterly spending trends, FOI-related articles, year-on-year supplier changes. Key by quarter not year to avoid exhaustion. | 1 hr | 4x more article variety |
| E3 | **Pre-compute spending stats** — Instead of loading 160MB of JSON, save stats during ETL (a `spending-stats.json` per council). article_pipeline.py reads the 10KB stats file. | 30 min | 90% memory reduction |
| E4 | **Deploy News Lancashire more often** — Currently 1x/day at 10am. The pipeline runs every 30 mins with fresh articles. Add a second deploy at 6pm, or trigger deploy when article count increases. | 15 min | Fresher content on site |

### Tier 3 — Quality Improvements (this month)

| # | Improvement | Effort | Impact |
|---|-------------|--------|--------|
| Q1 | **Stronger fact verification** — Parse £ figures from LLM output and compare against data_context. Flag any number not found in the source data. | 2 hr | Prevents hallucinated numbers |
| Q2 | **Borough-weighted crawling** — RSS feeds are Lancashire-wide but site focuses on East Lancashire. Weight source selection towards Burnley/Hyndburn/Pendle/Rossendale feeds. Add more hyperlocal RSS sources. | 1 hr | Better coverage for target boroughs |
| Q3 | **Upgrade News Burnley** — Hugo site instead of single HTML page. Individual article pages, sitemap.xml, RSS feed, Cloudflare Analytics. Reuse News Lancashire Hugo theme. | 3 hr | SEO, discoverability, analytics |
| Q4 | **AI DOGE article quality** — Single-article rewrites instead of batch mode in ai_rewriter.py. Add rewrite validation (check it's not just copying the original). Humaniser pass for natural voice. | 2 hr | Better reading experience |
| Q5 | **Populate `tags` field** — Auto-tag articles using LLM or keyword extraction. Enables tag-based filtering on the React frontend. | 1 hr | Better navigation |

### Tier 4 — New Features (future)

| # | Feature | Effort | Impact |
|---|---------|--------|--------|
| N1 | **Cross-platform article syndication** — AI DOGE articles could appear on News Lancashire, and vice versa. Spending articles are news. | 2 hr | 2x audience reach |
| N2 | **Article freshness monitoring** — Cron that checks: any council with <3 articles in last 7 days → WhatsApp alert | 30 min | Prevents content gaps |
| N3 | **Per-borough News Lancashire sites** — Same pattern as News Burnley but for Hyndburn, Pendle, Rossendale. Filter + deploy. | 2 hr per borough | 4 more local news sites |
| N4 | **Newsletter generation** — Weekly email digest from News Lancashire top articles. Use Mailu on vps-main. | 3 hr | Direct audience engagement |
| N5 | **Trending article detection** — Surface articles with rising social engagement or multiple-source coverage. Pin to homepage. | 2 hr | Better engagement |

---

## 6. Proposed New Cron Schedule

```
vps-news:
  */30 * * * *   pipeline_v4.sh (crawl → AI → export → News Burnley sync)
  (unchanged — every 30 min)

vps-main:
  05:00  sync_repos.sh
  07:00  data_monitor.py
  08:00  auto_pipeline.py
  09:00  article_pipeline.py --max-articles 2
  10:00  deploy_newslancashire.sh
  10:30  deploy_newsburnley.sh
  18:00  deploy_newslancashire.sh          ← NEW: evening deploy for afternoon articles
  18:30  deploy_newsburnley.sh             ← NEW: evening deploy
  20:00  article_freshness_check.sh        ← NEW: alert if any council has 0 articles in 7 days
```

---

## 7. Priority Order

1. ~~**F1 + F2 + F4**~~ — ✅ Done (9 Feb 2026). F2 was not a bug (deduplication, not cap).
2. ~~**F3**~~ — ✅ Done (9 Feb night). `normalise_date_iso()` now called on INSERT in `crawler_v3.py`. 143 legacy non-ISO dates fixed.
3. ~~**E1**~~ — ⚠️ Partially done (10 Feb). All scripts use same provider chain. Full module consolidation remaining.
4. **E2** — More topic templates (1 hr)
5. **E4** — Deploy twice daily (15 min)
6. **Q1** — Stronger fact verification (2 hr)
7. **Everything else** — as time allows

**Estimated total for Tiers 1+2: ~4 hours of work for a dramatically more robust pipeline.**

---

## 8. Live Site Audit (9 Feb 2026 night)

### Image Issues Found & Fixed

**4 missing images** referenced by `article_pipeline.py` or articles-index.json that don't exist in `public/images/articles/`:

| Missing Image | Remapped To | Reason |
|---------------|-------------|--------|
| `spending.jpg` | `finance.jpg` | article_pipeline.py `ARTICLE_IMAGES['spending']` |
| `budget.jpg` | `finance.jpg` | article_pipeline.py `ARTICLE_IMAGES['budget']` |
| `services.jpg` | `council-meeting.jpg` | article_pipeline.py `ARTICLE_IMAGES['services']` |
| `transparency.jpg` | `documents.jpg` | Rossendale articles-index.json |
| `contracts.jpg` | `legal.jpg` | Rossendale articles-index.json |
| `council.jpg` | `council-meeting.jpg` | Rossendale articles-index.json |

**Fixes applied:**
1. ✅ Remapped `ARTICLE_IMAGES` in `article_pipeline.py` to use only images that exist
2. ✅ Fixed 4 broken refs in Rossendale `articles-index.json`
3. ✅ Added `onError` fallback to `News.jsx` and `ArticleView.jsx` — broken images now hide gracefully
4. ✅ Committed + pushed to trigger CI/CD redeploy

**Available images** in `public/images/articles/` (14 total):
construction, council-meeting, credit-card, documents, finance, government, insurance, legal, magnifying-glass, outsourcing, pizza, social-media, streaming-tv, waste

### News Page UX Improvements (backlog)

| # | Improvement | Effort | Impact |
|---|-------------|--------|--------|
| U1 | **Placeholder image for articles without images** — Instead of hiding broken images, show a council-branded SVG placeholder with the category icon | 30 min | Professional appearance |
| U2 | **Article date variety** — All articles show "7 Feb 2026" or "9 Feb 2026". Future auto-generated articles need staggered dates or "updated" dates | 15 min | More dynamic appearance |
| U3 | **Empty state for councils with few articles** — Rossendale has 7, others have 19-44. Consider "More articles coming soon" messaging | 15 min | Better UX for thin councils |
| U4 | **Search/filter by keyword** — Currently only category filter exists. Text search across titles+summaries would help with 44 Burnley articles | 1 hr | Findability |
| U5 | **Pagination or "Load more"** — 44 articles on one page is heavy. Lazy-load after first 12 | 30 min | Performance + UX |
| U6 | **Related articles** — At bottom of ArticleView, suggest 2-3 articles in same category | 30 min | Engagement, reduce bounce |
| U7 | **RSS feed** — Generate `articles.xml` during build for each council. Free syndication, Google News pickup | 1 hr | SEO + reach |

---

## 9. End-to-End Deployment Audit (9 Feb 2026 night)

### News Lancashire: Pipeline → Live Site

| Step | Status | Notes |
|------|--------|-------|
| Cron runs every 30 min | ✅ Working | `pipeline_v4.sh` runs all 9 phases |
| Crawl + ingest | ✅ Working | 963 articles in DB, new articles arriving |
| AI rewrite (Gemini primary) | ✅ Working | Gemini 2.5 Flash is now primary (free, 500 req/day). Kimi as fallback. Content filter retries individually, skips filtered. |
| AI analysis (Gemini primary) | ✅ Working | Same Gemini-first chain. Rate limiter tracks daily usage. |
| DeepSeek fallback | ❌ Dead | HTTP 402 Payment Required. Credits exhausted. Mitigated: Gemini is free primary. |
| Groq fallback | ❌ Blocked | Cloudflare error 1010 blocks VPS IPs. In chain but never succeeds server-side. |
| Export to JSON | ✅ Working | 802 articles exported (deduped) |
| Hugo build | ✅ Working | 1200 HTML pages, ~15s build time |
| Deploy to Cloudflare Pages | ✅ Working | 1426 files deployed, tested manually |
| Live site (newslancashire.co.uk) | ✅ HTTP 200 | Serving fresh content |

### News Burnley: Pipeline → Live Site

| Step | Status | Notes |
|------|--------|-------|
| News Burnley sync (Phase 9) | ✅ Working | 50 articles filtered for Burnley |
| Rsync to vps-main | ✅ Working | 2 files (index.html + burnley-news.json) |
| Deploy to Cloudflare Pages | ✅ Working | Tested manually, success |
| Live site (newsburnley.co.uk) | ✅ HTTP 200 | Serving content |
| Last-Modified header | ⚠️ Stale | Shows "Fri, 06 Feb 2026" — 3 days old. Cron deploys weren't running (NVM bug). Now fixed. |

### Bugs Fixed This Session

| Bug | Root Cause | Fix |
|-----|-----------|-----|
| deploy_newslancashire.sh failing silently | NVM not installed on vps-main, `source "$NVM_DIR/nvm.sh"` fails | Removed NVM dependency — Node.js is global |
| deploy_newsburnley.sh hardcoded credentials | Cloudflare API token + account ID hardcoded in script | Load from vps-news `.env` via SSH |
| Kimi returning 400 on ai_rewriter | Content filter rejects batch with sensitive articles | Try individually, skip filtered articles |
| ai_analyzer model mismatch | Uses `kimi-latest` (may not exist) | Changed to `kimi-k2.5` |
| Dates still mixed format in DB | `normalise_date_iso()` only ran as migration, not on INSERT | Added to `insert_article()`, fixed 143 legacy dates |
| ai_digest_generator 400 errors | Same content filter issue | Added graceful handling, falls back to template |

### Manual Steps Still Needed

1. ~~**Push newslancashire to GitHub**~~ — ✅ Done (10 Feb 2026). 4 commits pushed to `tompickup23/newslancashire`. Deploy key added, remote set, branch `master`.
2. ~~**Top up DeepSeek credits**~~ — ✅ Mitigated (10 Feb 2026). Gemini 2.5 Flash is now free primary. DeepSeek no longer needed.
3. **Check Moonshot/Kimi credit balance** — API works but only used as fallback now. Check at platform.moonshot.ai.
