name: Build & Deploy Lancashire Councils

on:
  push:
    branches: [main]
    paths-ignore:
      - '*.md'
      - 'burnley-council/reports/**'
      - 'IMPROVEMENTS.md'
      - '.claude/**'
  workflow_dispatch:

concurrency:
  group: deploy-lancashire
  cancel-in-progress: false

permissions:
  contents: read

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    env:
      COUNCILS: "burnley:burnleycouncil hyndburn:hyndburncouncil pendle:pendlecouncil rossendale:rossendalecouncil lancaster:lancastercouncil ribble_valley:ribblevalleycouncil chorley:chorleycouncil south_ribble:southribblecouncil lancashire_cc:lancashirecc blackpool:blackpoolcouncil west_lancashire:westlancashirecouncil blackburn:blackburncouncil wyre:wyrecouncil preston:prestoncouncil fylde:fyldecouncil"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version-file: '.nvmrc'
          cache: npm

      - name: Install dependencies
        run: npm ci

      - name: Run tests
        run: npm test

      - name: Create deploy directory
        run: mkdir -p /tmp/lancashire-deploy

      # v4 monthly spending chunks for large councils are gitignored (~647MB).
      # Restore them from the previous deploy so spending pages stay live.
      # The Vite build plugin copies everything from burnley-council/data/{council}/ to public/data/.
      - name: Restore v4 spending chunks from previous deploy
        run: |
          V4_COUNCILS="lancashire_cc:lancashirecc blackpool:blackpoolcouncil blackburn:blackburncouncil"
          echo "Fetching spending data from previous deploy..."
          DEPLOY_URL="https://aidoge.co.uk/lancashire"
          RESTORED=0
          for entry in $V4_COUNCILS; do
            COUNCIL_ID="${entry%%:*}"
            SLUG="${entry##*:}"
            DEST="burnley-council/data/${COUNCIL_ID}"
            INDEX_URL="${DEPLOY_URL}/${SLUG}/data/spending-index.json"
            # Download spending-index.json
            if curl -sf "${INDEX_URL}" -o "${DEST}/spending-index.json"; then
              # Parse month file list from index and download each chunk
              CHUNKS=$(node -e "const idx=require('./${DEST}/spending-index.json'); const yrs=idx.years||{}; Object.values(yrs).forEach(y=>{if(y.months){Object.values(y.months).forEach(m=>console.log(m.file))}})")
              COUNT=0
              for CHUNK_FILE in $CHUNKS; do
                CHUNK_URL="${DEPLOY_URL}/${SLUG}/data/${CHUNK_FILE}"
                if curl -sf "${CHUNK_URL}" -o "${DEST}/${CHUNK_FILE}"; then
                  COUNT=$((COUNT + 1))
                fi
              done
              # Enable spending in config
              sed -i 's/"spending": false/"spending": true/' "${DEST}/config.json"
              echo "✓ ${COUNCIL_ID}: restored spending-index.json + ${COUNT} monthly chunks"
              RESTORED=$((RESTORED + 1))
            else
              echo "⚠ ${COUNCIL_ID}: no spending data in previous deploy (first deploy?)"
            fi
          done
          echo "Restored spending data for ${RESTORED}/3 councils"

      # Council registry defined in job env.COUNCILS above. To add a council, edit it there.
      # Builds run sequentially — they share public/data/ so cannot run in parallel.
      - name: Build all councils
        env:
          VITE_CF_ANALYTICS_TOKEN: ${{ secrets.CF_ANALYTICS_TOKEN }}
        run: |
          for entry in $COUNCILS; do
            COUNCIL_ID="${entry%%:*}"
            COUNCIL_SLUG="${entry##*:}"
            echo "::group::Building ${COUNCIL_ID}"
            VITE_COUNCIL="${COUNCIL_ID}" VITE_BASE="/lancashire/${COUNCIL_SLUG}/" npx vite build --outDir "/tmp/lancashire-deploy/${COUNCIL_SLUG}"
            echo "::endgroup::"
          done

      # Remove spending.json monoliths and v3 year chunks from v4 councils to save deploy size.
      # The v4 worker loads from spending-index.json + monthly chunks, not spending.json.
      - name: Clean v4 council deploy artifacts
        run: |
          V4_SLUGS="lancashirecc blackpoolcouncil blackburncouncil"
          for SLUG in $V4_SLUGS; do
            DIR="/tmp/lancashire-deploy/${SLUG}/data"
            if [ -f "${DIR}/spending-index.json" ]; then
              # Remove monolith spending.json + compressed variants (v4 uses chunks instead)
              rm -f "${DIR}/spending.json" "${DIR}/spending.json.gz" "${DIR}/spending.json.br"
              # Remove v3 year chunks (spending-YYYY-YY.json where YY > 12)
              # and compressed monthly chunks (GitHub Pages doesn't serve .gz/.br)
              for f in "${DIR}"/spending-20??-??.json*; do
                BASE=$(basename "$f")
                # Extract last 2 digits before .json — year chunks have 13-99, months have 01-12
                SUFFIX=$(echo "$BASE" | sed 's/.*-\([0-9][0-9]\)\.json.*/\1/')
                if [ "$SUFFIX" -gt 12 ] 2>/dev/null; then
                  rm -f "$f"
                elif echo "$BASE" | grep -qE '\.(gz|br)$'; then
                  rm -f "$f"
                fi
              done
              echo "✓ Cleaned ${SLUG}: kept spending-index.json + monthly chunks only"
            fi
          done

      # Hub pages — root 404.html is the ONLY 404 GitHub Pages reads for SPA routing
      - name: Copy hub pages and generate sitemap
        run: |
          cp burnley-council/hub/index.html /tmp/lancashire-deploy/index.html
          cp burnley-council/hub/404.html /tmp/lancashire-deploy/404.html
          echo 'aidoge.co.uk' > /tmp/lancashire-deploy/CNAME
          cp public/robots.txt /tmp/lancashire-deploy/robots.txt
          # Generate sitemap index dynamically from council registry
          {
            echo '<?xml version="1.0" encoding="UTF-8"?>'
            echo '<sitemapindex xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">'
            for entry in $COUNCILS; do
              COUNCIL_SLUG="${entry##*:}"
              echo "  <sitemap><loc>https://aidoge.co.uk/lancashire/${COUNCIL_SLUG}/sitemap.xml</loc></sitemap>"
            done
            echo '</sitemapindex>'
          } > /tmp/lancashire-deploy/sitemap.xml

      - name: Deploy to GitHub Pages
        run: |
          npx gh-pages \
            -d /tmp/lancashire-deploy \
            --repo https://x-access-token:${{ secrets.DEPLOY_TOKEN }}@github.com/tompickup23/lancashire.git \
            --no-history \
            --user "AI DOGE Deploy <deploy@aidoge.co.uk>"

      - name: Verify deployment
        if: success()
        run: |
          echo "Waiting 30s for GitHub Pages CDN propagation..."
          sleep 30
          FAIL=0
          # Check hub
          CODE=$(curl -s -o /dev/null -w "%{http_code}" "https://aidoge.co.uk/")
          echo "https://aidoge.co.uk/ → HTTP ${CODE}"
          if [ "$CODE" != "200" ]; then FAIL=1; fi
          # Check each council
          for entry in $COUNCILS; do
            COUNCIL_SLUG="${entry##*:}"
            CODE=$(curl -s -o /dev/null -w "%{http_code}" "https://aidoge.co.uk/lancashire/${COUNCIL_SLUG}/")
            echo "https://aidoge.co.uk/lancashire/${COUNCIL_SLUG}/ → HTTP ${CODE}"
            if [ "$CODE" != "200" ]; then FAIL=1; fi
          done
          if [ "$FAIL" = "1" ]; then
            echo "Some pages returned non-200 — CDN may still be propagating (takes ~10 min)"
          else
            echo "All pages returned 200"
          fi
        continue-on-error: true
